{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab on Logistic Regression is a Python adaptation of p. 161-163 of \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. Adapted by R. Jordan Crouser at Smith College for SDS293: Machine Learning (Spring 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.3 Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to the ${\\tt Smarket}$ data from ${\\tt ISLR}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>1.3491</td>\n",
       "      <td>1.392</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.392</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>1.4450</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.403</td>\n",
       "      <td>1.392</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.4078</td>\n",
       "      <td>0.027</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>1.392</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.614</td>\n",
       "      <td>1.1640</td>\n",
       "      <td>1.303</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.303</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>1.392</td>\n",
       "      <td>0.213</td>\n",
       "      <td>1.2326</td>\n",
       "      <td>0.287</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.287</td>\n",
       "      <td>1.303</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>1.392</td>\n",
       "      <td>1.3090</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.498</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1.303</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>1.2580</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1.303</td>\n",
       "      <td>0.027</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>0.680</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.680</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1.303</td>\n",
       "      <td>1.0531</td>\n",
       "      <td>0.701</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.701</td>\n",
       "      <td>0.680</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1.1498</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "Year                                                                  \n",
       "2001-01-01  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2001-01-01  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2001-01-01  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "2001-01-01 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "2001-01-01  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up\n",
       "2001-01-01  0.213  0.614 -0.623  1.032  0.959  1.3491  1.392        Up\n",
       "2001-01-01  1.392  0.213  0.614 -0.623  1.032  1.4450 -0.403      Down\n",
       "2001-01-01 -0.403  1.392  0.213  0.614 -0.623  1.4078  0.027        Up\n",
       "2001-01-01  0.027 -0.403  1.392  0.213  0.614  1.1640  1.303        Up\n",
       "2001-01-01  1.303  0.027 -0.403  1.392  0.213  1.2326  0.287        Up\n",
       "2001-01-01  0.287  1.303  0.027 -0.403  1.392  1.3090 -0.498      Down\n",
       "2001-01-01 -0.498  0.287  1.303  0.027 -0.403  1.2580 -0.189      Down\n",
       "2001-01-01 -0.189 -0.498  0.287  1.303  0.027  1.0980  0.680        Up\n",
       "2001-01-01  0.680 -0.189 -0.498  0.287  1.303  1.0531  0.701        Up\n",
       "2001-01-01  0.701  0.680 -0.189 -0.498  0.287  1.1498 -0.562      Down"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Smarket.csv', usecols=range(1,10), index_col=0, parse_dates=True)\n",
    "# df = pd.read_csv('data/Smarket.csv')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will perform LDA on the ${\\tt Smarket}$ data from the ${\\tt ISLR}$ package. In ${\\tt Python}$, we can fit a LDA model using the ${\\tt LDA()}$ function, which is part of the ${\\tt lda}$ module of the ${\\tt sklearn}$ library. As we did with logistic regression and KNN, we'll fit the model using only the observations before 2005, and then test the model on the data from 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49198397 0.50801603]\n"
     ]
    }
   ],
   "source": [
    "X_train = df[:'2004'][['Lag1','Lag2']]\n",
    "y_train = df[:'2004']['Direction']\n",
    "\n",
    "X_test = df['2005':][['Lag1','Lag2']]\n",
    "y_test = df['2005':]['Direction']\n",
    "\n",
    "lda = LDA()\n",
    "model = lda.fit(X_train, y_train)\n",
    "\n",
    "print(model.priors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA output indicates prior probabilities of ${\\hat{\\pi}}_1 = 0.492$ and ${\\hat{\\pi}}_2 = 0.508$; in other words,\n",
    "49.2% of the training observations correspond to days during which the\n",
    "market went down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n"
     ]
    }
   ],
   "source": [
    "print(model.means_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above provides the group means; these are the average\n",
    "of each predictor within each class, and are used by LDA as estimates\n",
    "of $\\mu_k$. These suggest that there is a tendency for the previous 2 days’\n",
    "returns to be negative on days when the market increases, and a tendency\n",
    "for the previous days’ returns to be positive on days when the market\n",
    "declines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05544078 -0.0443452 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients of linear discriminants output provides the linear\n",
    "combination of ${\\tt Lag1}$ and ${\\tt Lag2}$ that are used to form the LDA decision rule. In other words, these are the multipliers of the elements of ${X = x}$ in 4.19:\n",
    "\n",
    "${\\delta_k(x) = x^T\\Sigma^{-1}\\mu_k - \\frac{1}{2}\\mu_k^T\\Sigma^{-1}\\mu_k + log\\pi_k}$\n",
    "\n",
    "If $−0.0554\\times{\\tt Lag1}−0.0443\\times{\\tt Lag2}$ is large, then the LDA classifier will\n",
    "predict a market increase, and if it is small, then the LDA classifier will\n",
    "predict a market decline. **Note**: these coefficients differ from those produced by ${\\tt R}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ${\\tt predict()}$ function returns a list of LDA’s predictions about the movement of the market on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Down', 'Up'], dtype='<U4'), array([ 70, 182]))\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_test)\n",
    "print(np.unique(pred, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model assigned 70 observations to the \"Down\" class, and 182 observations to the \"Up\" class. Let's check out the confusion matrix to see how this model is doing. We'll want to compare the **predicted class** (which we can find in ${\\tt pred}$) to the **true class** (found in ${\\tt y\\_test})$.\n",
    "\n",
    "![image.jpg](table4-6.jpg)\n",
    "\n",
    "![image.jpg](table4-7.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35  35]\n",
      " [ 76 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.500     0.315     0.387       111\n",
      "          Up      0.582     0.752     0.656       141\n",
      "\n",
      "    accuracy                          0.560       252\n",
      "   macro avg      0.541     0.534     0.522       252\n",
      "weighted avg      0.546     0.560     0.538       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred, y_test))\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the predicted _probabilities_ using the ${\\tt predict\\_proba()}$ function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_p = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a 50% threshold to the posterior probabilities allows us to recreate\n",
    "the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([ 70, 182]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(pred_p[:,1]>0.5, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the posterior probability output by the model corresponds to\n",
    "the probability that the market will **increase** (opposite of R output in text):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.5093037238790318' 'Up']\n",
      " ['0.4880011537380811' 'Down']\n",
      " ['0.510484773063352' 'Up']\n",
      " ['0.5293238777881214' 'Up']\n",
      " ['0.5255407143881711' 'Up']\n",
      " ['0.5200416608518921' 'Up']\n",
      " ['0.5064224705341396' 'Up']\n",
      " ['0.4969106228816935' 'Down']\n",
      " ['0.5021193878585957' 'Up']\n",
      " ['0.5113669134834818' 'Up']]\n"
     ]
    }
   ],
   "source": [
    "print(np.stack((pred_p[10:20,1], pred[10:20])).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to use a posterior probability threshold other than 50% in\n",
    "order to make predictions, then we could easily do so. For instance, suppose\n",
    "that we wish to predict a market decrease only if we are very certain that the\n",
    "market will indeed decrease on that day—say, if the posterior probability\n",
    "is at least 90%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False]), array([252]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(pred_p[:,1]>0.9, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No days in 2005 meet that threshold! In fact, the greatest posterior probability\n",
    "of decrease in all of 2005 was 54.2%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5422132554518978"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred_p[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.4 Quadratic Discriminant Analysis\n",
    "We will now fit a QDA model to the ${\\tt Smarket}$ data. QDA is implemented\n",
    "in ${\\tt sklearn}$ using the ${\\tt QDA()}$ function, which is part of the ${\\tt qda}$ module. The\n",
    "syntax is identical to that of ${\\tt LDA()}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49198397 0.50801603]\n",
      "[[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "model2 = qda.fit(X_train, y_train)\n",
    "print(model2.priors_)\n",
    "print(model2.means_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output contains the group means. But it does not contain the coefficients\n",
    "of the linear discriminants, because the QDA classifier involves a\n",
    "_quadratic_, rather than a linear, function of the predictors. The ${\\tt predict()}$\n",
    "function works in exactly the same fashion as for LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Down', 'Up'], dtype=object), array([ 50, 202]))\n",
      "[[ 30  20]\n",
      " [ 81 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.600     0.270     0.373       111\n",
      "          Up      0.599     0.858     0.706       141\n",
      "\n",
      "    accuracy                          0.599       252\n",
      "   macro avg      0.600     0.564     0.539       252\n",
      "weighted avg      0.599     0.599     0.559       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2=model2.predict(X_test)\n",
    "print(np.unique(pred2, return_counts=True))\n",
    "print(confusion_matrix(pred2, y_test))\n",
    "print(classification_report(y_test, pred2, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the QDA predictions are accurate almost 60% of the time,\n",
    "even though the 2005 data was not used to fit the model. This level of accuracy\n",
    "is quite impressive for stock market data, which is known to be quite\n",
    "hard to model accurately. \n",
    "\n",
    "This suggests that the quadratic form assumed\n",
    "by QDA may capture the true relationship more accurately than the linear\n",
    "forms assumed by LDA and logistic regression. However, we recommend\n",
    "evaluating this method’s performance on a larger test set before betting\n",
    "that this approach will consistently beat the market!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Application to Carseats Data\n",
    "Let's see how the ${\\tt LDA/QDA}$ approach performs on the ${\\tt Carseats}$ data set, which is\n",
    "included with ${\\tt ISLR}$. \n",
    "\n",
    "Recall: this is a simulated data set containing sales of child car seats at 400 different stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.81</td>\n",
       "      <td>124</td>\n",
       "      <td>113</td>\n",
       "      <td>13</td>\n",
       "      <td>501</td>\n",
       "      <td>72</td>\n",
       "      <td>Bad</td>\n",
       "      <td>78</td>\n",
       "      <td>16</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.63</td>\n",
       "      <td>115</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>Medium</td>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.85</td>\n",
       "      <td>136</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>425</td>\n",
       "      <td>120</td>\n",
       "      <td>Good</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.54</td>\n",
       "      <td>132</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>124</td>\n",
       "      <td>Medium</td>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.69</td>\n",
       "      <td>132</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>124</td>\n",
       "      <td>Medium</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "5  10.81        124     113           13         501     72       Bad   78   \n",
       "6   6.63        115     105            0          45    108    Medium   71   \n",
       "7  11.85        136      81           15         425    120      Good   67   \n",
       "8   6.54        132     110            0         108    124    Medium   76   \n",
       "9   4.69        132     113            0         131    124    Medium   76   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  \n",
       "5         16    No  Yes  \n",
       "6         15   Yes   No  \n",
       "7         10   Yes  Yes  \n",
       "8         10    No   No  \n",
       "9         17    No  Yes  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/Carseats.csv')\n",
    "df2.head(10)\n",
    "# df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can build a model that predicts ${\\tt ShelveLoc}$, the shelf location (Bad, Good, or Medium) of the product at each store. Don't forget to hold out some of the data for testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "predictors = ['Sales', 'CompPrice', 'Price']\n",
    "train_len = round(len(df2) * 0.70)\n",
    "X_train = df2[:train_len][predictors]\n",
    "X_test = df2[train_len:][predictors]\n",
    "y_train = df2[0:train_len][\"ShelveLoc\"]\n",
    "y_test = df2[train_len:][\"ShelveLoc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24285714 0.18928571 0.56785714]\n"
     ]
    }
   ],
   "source": [
    "model2 = lda.fit(X_train, y_train)\n",
    "print(model2.priors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.85070287  0.08097587 -0.08174572]\n",
      " [ 1.34498179 -0.13053429  0.13018438]\n",
      " [-0.08450466  0.00888024 -0.00843436]]\n"
     ]
    }
   ],
   "source": [
    "print(model2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  3]\n",
      " [ 0 17  8]\n",
      " [15 15 49]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad      0.812     0.464     0.591        28\n",
      "        Good      0.680     0.531     0.596        32\n",
      "      Medium      0.620     0.817     0.705        60\n",
      "\n",
      "    accuracy                          0.658       120\n",
      "   macro avg      0.704     0.604     0.631       120\n",
      "weighted avg      0.681     0.658     0.649       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred2, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get credit for this lab, please post your answers to the following questions:\n",
    "\n",
    "- What was your approach to building the model?\n",
    "- How did your model perform?\n",
    "- Was anything easier or more challenging than you anticipated?\n",
    "\n",
    "to Piazza: https://piazza.com/class/igwiv4w3ctb6rg?cid=23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
